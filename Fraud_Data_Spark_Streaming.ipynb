{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.5.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 pyspark-shell'\n",
    "\n",
    "checkpoint_dir=\"spark_streaming_check\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FraudDetection\") \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"16MB\") \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"Australia/Melbourne\") \\\n",
    "    .config(\"spark.sql.streaming.forceDeleteTempCheckpointLocation\", \"true\") \\\n",
    "    .config(\"spark.sql.streaming.checkpointLocation\",checkpoint_dir) \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- birthdate: date (nullable = true)\n",
      " |-- first_join_date: date (nullable = true)\n",
      "\n",
      "root\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- cat_level1: string (nullable = true)\n",
      " |-- cat_level2: string (nullable = true)\n",
      " |-- cat_level3: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- baseColour: string (nullable = true)\n",
      " |-- season: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- usage: string (nullable = true)\n",
      " |-- productDisplayName: string (nullable = true)\n",
      " |-- category_id: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- Is_fraud: string (nullable = true)\n",
      "\n",
      "+-----------+----------+-----------+--------------------+--------------------+------+----------+---------------+\n",
      "|customer_id|first_name|  last_name|            username|               email|gender| birthdate|first_join_date|\n",
      "+-----------+----------+-----------+--------------------+--------------------+------+----------+---------------+\n",
      "|       2870|      Lala|    Maryati|671a0865-ac4e-4dc...|671a0865_ac4e_4dc...|     F|1996-06-14|     2019-07-21|\n",
      "|       8193|  Maimunah| Laksmiwati|83be2ba7-8133-48a...|83be2ba7_8133_48a...|     F|1993-08-16|     2017-07-16|\n",
      "|       7279|   Bakiman|Simanjuntak|3250e5a3-1d23-467...|3250e5a3_1d23_467...|     M|1989-01-23|     2020-08-23|\n",
      "|      88813|   Cahyadi|  Maheswara|df797edf-b465-4a8...|df797edf_b465_4a8...|     M|1991-01-05|     2021-10-03|\n",
      "|      82542|   Irnanto|     Wijaya|36ab08e1-03de-42a...|36ab08e1_03de_42a...|     M|2000-07-15|     2021-04-11|\n",
      "+-----------+----------+-----------+--------------------+--------------------+------+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------+-------------+-------------+--------------------+\n",
      "|category_id|   cat_level1|   cat_level2|          cat_level3|\n",
      "+-----------+-------------+-------------+--------------------+\n",
      "|          1|Personal Care|       Makeup|             Compact|\n",
      "|          2|   Free Items|   Free Gifts|                Ties|\n",
      "|          3|     Footwear|        Shoes|        Casual Shoes|\n",
      "|          4|Personal Care|Bath and Body| Body Wash and Scrub|\n",
      "|          5|Personal Care|    Skin Care|Face Wash and Cle...|\n",
      "+-----------+-------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+------+----------+------+----+------+--------------------+-----------+\n",
      "|   id|gender|baseColour|season|year| usage|  productDisplayName|category_id|\n",
      "+-----+------+----------+------+----+------+--------------------+-----------+\n",
      "|29789|   Men|      Pink|Summer|2013|Casual|Basics Men Pack o...|         40|\n",
      "|53137| Women|     Brown|Winter|2015|Casual|Catwalk Women Bro...|         83|\n",
      "|21129| Women|       Red|  Fall|2011|Casual|s.Oliver Women Pr...|         49|\n",
      "| 6229|   Men|     Black|Summer|2011|Casual|Lee Men's Shot Bl...|         40|\n",
      "|40580| Women|     White|Summer|2012|Casual|   W Women White Top|         49|\n",
      "+-----+------+----------+------+----+------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----------+\n",
      "|          session_id|customer_id|\n",
      "+--------------------+-----------+\n",
      "|3abaa6ce-e320-4e5...|       5868|\n",
      "|2ee5ead1-f13e-475...|       4774|\n",
      "|93325fb6-eb00-426...|       4774|\n",
      "|bcad5a61-1b67-448...|       4774|\n",
      "|df1042ab-13e6-407...|       4774|\n",
      "+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------+\n",
      "|      transaction_id|Is_fraud|\n",
      "+--------------------+--------+\n",
      "|9e81cadd-3f76-4bb...|    true|\n",
      "|204532ae-b268-4d2...|    true|\n",
      "|880767b5-a94c-4fb...|    true|\n",
      "|780aa6e8-0671-4fb...|    true|\n",
      "|737f279a-bb52-4f3...|    true|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType, TimestampType, ArrayType\n",
    "\n",
    "# Customer Schema\n",
    "customer_schema = StructType([\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"first_name\", StringType(), True),\n",
    "    StructField(\"last_name\", StringType(), True),\n",
    "    StructField(\"username\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"birthdate\", DateType(), True),\n",
    "    StructField(\"first_join_date\", DateType(), True)\n",
    "])\n",
    "\n",
    "# Category Schema\n",
    "category_schema = StructType([\n",
    "    StructField(\"category_id\", IntegerType(), True),\n",
    "    StructField(\"cat_level1\", StringType(), True),\n",
    "    StructField(\"cat_level2\", StringType(), True),\n",
    "    StructField(\"cat_level3\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Product Schema\n",
    "product_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"baseColour\", StringType(), True),\n",
    "    StructField(\"season\", StringType(), True),\n",
    "    StructField(\"year\", IntegerType(), True),\n",
    "    StructField(\"usage\", StringType(), True),\n",
    "    StructField(\"productDisplayName\", StringType(), True),\n",
    "    StructField(\"category_id\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Customer Session Schema\n",
    "customer_session_schema = StructType([\n",
    "    StructField(\"session_id\", StringType(), True),\n",
    "    StructField(\"customer_id\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Fraud Transaction Schema\n",
    "fraud_transaction_schema = StructType([\n",
    "    StructField(\"transaction_id\", StringType(), True),\n",
    "    StructField(\"Is_fraud\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "# Loading CSV Files with verified paths.\n",
    "category_df = spark.read.csv(\"category.csv\", schema=category_schema, header=True)\n",
    "customer_df = spark.read.csv(\"customer.csv\", schema=customer_schema, header=True)\n",
    "product_df = spark.read.csv(\"product.csv\", schema=product_schema, header=True)\n",
    "customer_session_df = spark.read.csv(\"customer_session.csv\", schema=customer_session_schema, header=True)\n",
    "fraud_transaction_df = spark.read.csv(\"fraud_transaction.csv\", schema=fraud_transaction_schema, header=True)\n",
    "\n",
    "# To print the schemas and show some data to verify\n",
    "customer_df.printSchema()\n",
    "category_df.printSchema()\n",
    "product_df.printSchema()\n",
    "customer_session_df.printSchema()\n",
    "fraud_transaction_df.printSchema()\n",
    "\n",
    "# To show some rows for verification\n",
    "customer_df.show(5)\n",
    "category_df.show(5)\n",
    "product_df.show(5)\n",
    "customer_session_df.show(5)\n",
    "fraud_transaction_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "# Configuration\n",
    "hostip = \"kafka\"\n",
    "topic = \"browsing-behavior-topic\"\n",
    "\n",
    "# Read data from Kafka topic\n",
    "browsing_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", f'{hostip}:9092') \\\n",
    "    .option(\"subscribe\", topic) \\\n",
    "    .load()\n",
    "\n",
    "transaction_topic = \"transactions-topic\"  # Kafka topic for transaction data\n",
    "\n",
    "# Read data from Kafka topic for transactions\n",
    "transaction_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", f'{hostip}:9092') \\\n",
    "    .option(\"subscribe\", transaction_topic) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "browsing_df.printSchema()\n",
    "transaction_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast key and value as STRING\n",
    "browsing_df = browsing_df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "\n",
    "# Define schema for Kafka value.\n",
    "schema = StructType([\n",
    "    StructField(\"session_id\", StringType(), True),\n",
    "    StructField(\"event_type\", StringType(), True),\n",
    "    StructField(\"event_time\", StringType(), True),\n",
    "    StructField(\"traffic_source\", StringType(), True),\n",
    "    StructField(\"device_type\", StringType(), True),\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"ts\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Parse the JSON data in 'value' column\n",
    "parsed_browsing_df = browsing_df.withColumn(\"data\", from_json(col(\"value\"), schema)).select(\"data.*\")\n",
    "\n",
    "# Cast key and value as STRING\n",
    "transaction_df = transaction_df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "\n",
    "# Define schema for Kafka value (transaction data)\n",
    "transaction_schema = StructType([\n",
    "    StructField(\"created_at\", StringType(), True),\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"transaction_id\", StringType(), True),\n",
    "    StructField(\"session_id\", StringType(), True),\n",
    "    StructField(\"product_metadata\", StringType(), True),\n",
    "    StructField(\"payment_method\", StringType(), True),\n",
    "    StructField(\"payment_status\", StringType(), True),\n",
    "    StructField(\"promo_amount\", StringType(), True),\n",
    "    StructField(\"promo_code\", StringType(), True),\n",
    "    StructField(\"shipment_fee\", StringType(), True),\n",
    "    StructField(\"shipment_location_lat\", StringType(), True),\n",
    "    StructField(\"shipment_location_long\", StringType(), True),\n",
    "    StructField(\"total_amount\", StringType(), True),\n",
    "    StructField(\"clear_payment\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Parse the JSON data in the 'value' column\n",
    "parsed_transaction_df = transaction_df.withColumn(\"data\", from_json(col(\"value\"), transaction_schema)).select(\"data.*\")\n",
    "\n",
    "schema_product_metadata = ArrayType(StructType([\n",
    "    # define the data type for id of product in product metadata column\n",
    "    StructField(\"product_id\", IntegerType(), True),\n",
    "    # define the data type for quantity in product metadata column\n",
    "    StructField(\"quantity\", IntegerType(), True),\n",
    "    # define the data type for item price of product in product metadata column\n",
    "    StructField(\"item_price\", IntegerType(), True)\n",
    "]))\n",
    "# Using to_json function and the defined schema we get the required structure of each element in the product metadata column\n",
    "parsed_transaction_df = parsed_transaction_df.withColumn(\"product_metadata\", from_json(col(\"product_metadata\"), schema_product_metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- event_time: string (nullable = true)\n",
      " |-- traffic_source: string (nullable = true)\n",
      " |-- device_type: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- ts: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- product_metadata: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- product_id: integer (nullable = true)\n",
      " |    |    |-- quantity: integer (nullable = true)\n",
      " |    |    |-- item_price: integer (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- payment_status: string (nullable = true)\n",
      " |-- promo_amount: string (nullable = true)\n",
      " |-- promo_code: string (nullable = true)\n",
      " |-- shipment_fee: string (nullable = true)\n",
      " |-- shipment_location_lat: string (nullable = true)\n",
      " |-- shipment_location_long: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- clear_payment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed_browsing_df.printSchema()\n",
    "# Output schema for transaction data\n",
    "parsed_transaction_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_unixtime, current_timestamp, unix_timestamp\n",
    "\n",
    "# For browsing_df: Cast only the required columns\n",
    "parsed_browsing_df = parsed_browsing_df.withColumn(\"event_time\", col(\"event_time\").cast(TimestampType())) \\\n",
    "    .withColumn(\"ts\", col(\"ts\").cast(IntegerType()))\n",
    "\n",
    "# For transaction_df: Cast only the required columns\n",
    "parsed_transaction_df = parsed_transaction_df.withColumn(\"created_at\", col(\"created_at\").cast(TimestampType())) \\\n",
    "    .withColumn(\"customer_id\", col(\"customer_id\").cast(IntegerType())) \\\n",
    "    .withColumn(\"promo_amount\", col(\"promo_amount\").cast(DoubleType())) \\\n",
    "    .withColumn(\"shipment_fee\", col(\"shipment_fee\").cast(DoubleType())) \\\n",
    "    .withColumn(\"shipment_location_lat\", col(\"shipment_location_lat\").cast(DoubleType())) \\\n",
    "    .withColumn(\"shipment_location_long\", col(\"shipment_location_long\").cast(DoubleType())) \\\n",
    "    .withColumn(\"total_amount\", col(\"total_amount\").cast(DoubleType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'ts' to 'event_ts' as a timestamp and filter out old data for browsing_df\n",
    "parsed_browsing_df = parsed_browsing_df.withColumn(\"event_ts\", from_unixtime(col(\"ts\")).cast(TimestampType())) \\\n",
    "    .filter((unix_timestamp(current_timestamp()) - unix_timestamp(col(\"event_ts\"))) <= 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For browsing data, write to memory\n",
    "query_browsing = parsed_browsing_df \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"browsing_query\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+----------+-----------------------+--------------+-----------+-----------+----------+-------------------+\n",
      "|session_id                          |event_type|event_time             |traffic_source|device_type|customer_id|ts        |event_ts           |\n",
      "+------------------------------------+----------+-----------------------+--------------+-----------+-----------+----------+-------------------+\n",
      "|cae032eb-9e06-4657-be66-8eb549bfe938|CL        |2024-01-01 06:32:36.459|MOBILE        |Android    |63151      |1728818038|2024-10-13 22:13:58|\n",
      "|79883a8d-083d-471a-b537-f470ed8d42b6|HP        |2024-01-01 06:32:37.163|MOBILE        |iOS        |72212      |1728818038|2024-10-13 22:13:58|\n",
      "|aea9b7f8-806a-4780-8758-a4ac58e107a2|SCR       |2024-01-01 06:32:52.867|MOBILE        |Android    |79087      |1728818038|2024-10-13 22:13:58|\n",
      "|9ae8dcd6-4338-4675-adc8-9189505be3fd|VI        |2024-01-01 06:33:14.705|MOBILE        |iOS        |35603      |1728818038|2024-10-13 22:13:58|\n",
      "|0ab976f4-b86b-450f-9a06-11a0d1d3eeed|SER       |2024-01-01 06:33:17.319|MOBILE        |Android    |68338      |1728818038|2024-10-13 22:13:58|\n",
      "|3889cdc1-986d-4846-b79f-613c30cf49a2|VI        |2024-01-01 06:33:43.348|MOBILE        |Android    |12090      |1728818038|2024-10-13 22:13:58|\n",
      "|d311c334-0b01-4719-87f1-888c8d6ff36a|HP        |2024-01-01 06:33:50.05 |MOBILE        |Android    |60358      |1728818038|2024-10-13 22:13:58|\n",
      "|76e0ec3b-18f9-4a05-a504-13b572b0e027|HP        |2024-01-01 06:33:54.562|MOBILE        |Android    |53108      |1728818038|2024-10-13 22:13:58|\n",
      "|166efaa8-1bd8-41a3-953e-b84a03f7ccfe|HP        |2024-01-01 06:33:55.593|MOBILE        |Android    |11858      |1728818038|2024-10-13 22:13:58|\n",
      "|43520f39-19c8-4545-83c3-f7eca548ddfa|SCR       |2024-01-01 06:33:55.851|MOBILE        |Android    |28820      |1728818038|2024-10-13 22:13:58|\n",
      "|e5dcfd96-df03-42f0-8f2a-46d246a91432|HP        |2024-01-01 06:34:02.565|MOBILE        |Android    |30956      |1728818038|2024-10-13 22:13:58|\n",
      "|b5b6c972-3ff7-47ab-bb8b-c5c382bf4e85|VI        |2024-01-01 06:34:04.562|MOBILE        |Android    |24911      |1728818038|2024-10-13 22:13:58|\n",
      "|3892de76-0c6d-4454-a3ee-fea535dd0f68|AP        |2024-01-01 06:34:04.763|MOBILE        |iOS        |28522      |1728818038|2024-10-13 22:13:58|\n",
      "|9d8501cd-af17-4f87-839f-6aa1724200df|CL        |2024-01-01 06:34:13.313|MOBILE        |Android    |19549      |1728818038|2024-10-13 22:13:58|\n",
      "|670f674d-f611-4e4d-ad16-ae94f52be3d6|CL        |2024-01-01 06:34:17.435|MOBILE        |Android    |92034      |1728818038|2024-10-13 22:13:58|\n",
      "|c5636f00-6e23-4020-ade3-e4ebc58c74e3|HP        |2024-01-01 06:34:24.719|MOBILE        |Android    |70974      |1728818038|2024-10-13 22:13:58|\n",
      "|35b7d947-1a2b-459b-9e89-d30d3d50f875|ATC       |2024-01-01 06:34:25.105|MOBILE        |Android    |43818      |1728818038|2024-10-13 22:13:58|\n",
      "|bb78bbf7-2471-4d69-8647-9a65ff73eb27|CO        |2024-01-01 06:34:29.019|MOBILE        |Android    |42863      |1728818038|2024-10-13 22:13:58|\n",
      "|672c581a-a96a-4fff-9fbe-9ebd32102f87|ATC       |2024-01-01 06:34:32.415|MOBILE        |Android    |50899      |1728818038|2024-10-13 22:13:58|\n",
      "|8c408594-dd43-4b91-93c0-d247caff5084|VI        |2024-01-01 06:34:33.606|MOBILE        |Android    |48485      |1728818038|2024-10-13 22:13:58|\n",
      "+------------------------------------+----------+-----------------------+--------------+-----------+-----------+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM browsing_query\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_browsing.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For transaction data, write to memory\n",
    "query_transaction = parsed_transaction_df \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"transaction_query\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------+------------------------------------+------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+--------------+------------+-------------+------------+---------------------+----------------------+------------+-------------+\n",
      "|created_at             |customer_id|transaction_id                      |session_id                          |product_metadata                                                                                                                                                                                                                                                                                          |payment_method|payment_status|promo_amount|promo_code   |shipment_fee|shipment_location_lat|shipment_location_long|total_amount|clear_payment|\n",
      "+-----------------------+-----------+------------------------------------+------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+--------------+------------+-------------+------------+---------------------+----------------------+------------+-------------+\n",
      "|2024-01-01 08:19:07.588|91202      |352a51ac-cba2-4e4f-8dfd-c84bb64ca3e6|b2eb986f-87f6-4209-ae53-648aaeb4f282|[{12586, 1, 503650}, {15140, 10, 166723}, {37540, 6, 109112}, {2722, 1, 214293}]                                                                                                                                                                                                                          |OVO           |Success       |0.0         |             |10000.0     |-0.141860676372223   |112.522769572143      |3049845.0   |1            |\n",
      "|2024-01-01 08:22:19.373|13163      |2d78e07e-271f-486e-a976-e5669f4764ad|a15ebf2c-26fb-4306-aec6-f919c38b0c3d|[{51614, 1, 136368}]                                                                                                                                                                                                                                                                                      |OVO           |Fail          |0.0         |             |10000.0     |-6.09732761307918    |106.943824915264      |146368.0    |0            |\n",
      "|2024-01-01 08:24:53.757|60776      |43ce5215-9277-45ef-931a-e40f7d8ab451|820e409a-51ba-406a-8b28-a8758f2da771|[{16914, 1, 78205}, {53857, 2, 157101}]                                                                                                                                                                                                                                                                   |Credit Card   |Success       |0.0         |             |0.0         |0.689631150333344    |111.928459538052      |392407.0    |1            |\n",
      "|2024-01-01 08:25:20.731|69465      |37c9ca6e-5360-43d9-a7d9-e5991b937af0|0b320efd-8809-4af5-baa0-18166c601f01|[{11771, 2, 233162}]                                                                                                                                                                                                                                                                                      |Debit Card    |Success       |0.0         |             |5000.0      |-6.15286837002468    |106.692792996988      |471324.0    |1            |\n",
      "|2024-01-01 08:29:35.139|43794      |8646da50-0629-4225-80c1-3f411b09f331|b8ca6f4f-144a-4b84-a280-bd07c9676583|[{52986, 1, 149643}]                                                                                                                                                                                                                                                                                      |LinkAja       |Fail          |0.0         |             |10000.0     |-7.33023839457002    |110.34254452467       |159643.0    |0            |\n",
      "|2024-01-01 08:31:03.901|93543      |08c6431b-4d5c-4608-a66d-0f6b15c5965c|bece73d7-55b1-42a6-9c48-e2b3e617ec61|[{6667, 1, 158894}]                                                                                                                                                                                                                                                                                       |OVO           |Fail          |0.0         |             |10000.0     |-6.75456164742522    |107.434966066062      |168894.0    |0            |\n",
      "|2024-01-01 08:31:23.718|41558      |b2456381-ed67-4b0f-b130-3bcfc0476fce|f1a2ad95-c7d1-4d2d-8d92-83184c40315b|[{28076, 1, 227309}, {9670, 1, 423210}]                                                                                                                                                                                                                                                                   |OVO           |Fail          |0.0         |             |10000.0     |-2.26027591167498    |115.34028397946       |660519.0    |0            |\n",
      "|2024-01-01 08:33:06.832|46387      |0d887413-5dac-410d-a97a-2c2d1ddd924e|a13a8140-2498-48a4-954e-162b19ec3adf|[{21379, 1, 135655}]                                                                                                                                                                                                                                                                                      |LinkAja       |Fail          |4991.0      |WEEKENDMANTAP|10000.0     |-4.52943261001737    |104.664058226997      |140664.0    |0            |\n",
      "|2024-01-01 08:38:11.618|18901      |8b41e189-f5c3-4d3f-8b4d-ea27c0394bfa|c47658b7-0810-4ef7-8fa1-3aae590a3eab|[{41311, 1, 300415}]                                                                                                                                                                                                                                                                                      |Credit Card   |Success       |3523.0      |WEEKENDMANTAP|10000.0     |-8.74089806369553    |117.224682918016      |306892.0    |1            |\n",
      "|2024-01-01 08:40:54.272|368        |364dabb0-4b0d-4d82-bd4e-9bc5100cfa51|55a93c38-bb51-443b-b647-30ebd545b72d|[{43273, 3, 245990}]                                                                                                                                                                                                                                                                                      |Credit Card   |Success       |5075.0      |LIBURDONG    |0.0         |-3.41091085126038    |126.744892053172      |732895.0    |1            |\n",
      "|2024-01-01 08:43:26.011|60392      |c00494ef-8aaf-4d85-9228-54889b36fb18|66e07383-d6b3-4d1d-883b-76b8d7c79c5a|[{3207, 1, 226183}]                                                                                                                                                                                                                                                                                       |Debit Card    |Success       |9268.0      |LIBURDONG    |10000.0     |0.247387582776524    |110.835817780061      |226915.0    |1            |\n",
      "|2024-01-01 08:46:48.368|74964      |fa3ddca5-a759-4589-b19a-a9c7657d756d|5af8f551-e411-4bdc-9a9e-a5f294f00686|[{40978, 2, 323497}]                                                                                                                                                                                                                                                                                      |Debit Card    |Fail          |0.0         |             |0.0         |-7.07645644603196    |110.937155183965      |646994.0    |0            |\n",
      "|2024-01-01 08:48:42.064|88991      |9722ca79-2ef5-4b77-a060-1d50b9e3b914|94bb13cc-45a9-4b4c-8daa-8d2fbd6e7796|[{14778, 3, 539753}]                                                                                                                                                                                                                                                                                      |Gopay         |Success       |0.0         |             |10000.0     |0.763607867407263    |124.003235560571      |1629259.0   |1            |\n",
      "|2024-01-01 08:49:56.115|27850      |772ab203-04b9-4177-a573-b287b2a05587|16b49100-a7d0-43a2-bfbd-5bd37ea16134|[{25273, 1, 177048}]                                                                                                                                                                                                                                                                                      |Credit Card   |Fail          |0.0         |             |10000.0     |-3.52946689404482    |102.159337687454      |187048.0    |0            |\n",
      "|2024-01-01 08:50:38.129|69822      |ae865ad1-c291-4a7b-b06e-4f5376a54348|47400ad1-4f57-42a3-804c-eb998effc7e4|[{54567, 1, 346799}, {44921, 1, 549134}, {25883, 2, 196776}, {43584, 1, 109713}, {59995, 1, 286217}, {39080, 1, 379560}, {58157, 1, 272064}, {36372, 3, 340682}, {11879, 1, 186043}, {15196, 1, 287961}, {19591, 1, 316419}, {8639, 1, 423814}, {7856, 1, 248626}, {17849, 1, 435044}, {32482, 1, 186317}]|Credit Card   |Success       |5109.0      |WEEKENDMANTAP|0.0         |-7.75525937048073    |109.71069065431       |5438200.0   |1            |\n",
      "|2024-01-01 08:51:45.638|33290      |94dab4a3-0fe2-4bb3-8cfd-cff761d4c0e2|e46bc807-be6c-4398-be87-2ebb3bbddd25|[{39043, 8, 137508}]                                                                                                                                                                                                                                                                                      |OVO           |Success       |5883.0      |WEEKENDMANTAP|50000.0     |-6.89830073089412    |107.43434179911       |1144181.0   |1            |\n",
      "|2024-01-01 08:54:14.196|25102      |c1437524-5287-452d-b921-25643eddf23e|97be2601-12ef-4f2d-ab62-988b7d296c2e|[{23564, 1, 217109}]                                                                                                                                                                                                                                                                                      |Credit Card   |Fail          |0.0         |             |0.0         |-1.9105452170552     |112.331576262449      |217109.0    |0            |\n",
      "|2024-01-01 08:55:29.091|78000      |f00be1f8-acd8-4336-b14f-4a34639978e0|8b62bc7f-9b2d-4c6a-8195-9d7d0dede25c|[{7117, 1, 178697}]                                                                                                                                                                                                                                                                                       |Debit Card    |Success       |4664.0      |WEEKENDSERU  |15000.0     |-7.07130361831833    |112.940243400417      |189033.0    |1            |\n",
      "|2024-01-01 08:56:47.738|71684      |390bd82f-4a49-4e2b-b7a9-cdce55e13c88|aaf2e14b-1bbc-4f62-b8bd-733f3c16b793|[{7243, 4, 379530}, {12093, 1, 85990}, {12004, 1, 177530}]                                                                                                                                                                                                                                                |Credit Card   |Success       |0.0         |             |10000.0     |-0.757719766510105   |133.688344973161      |1791640.0   |1            |\n",
      "|2024-01-01 08:57:44.316|59554      |13f0b107-71d1-4f6c-8ca4-acd07699a324|84c35e86-54be-4956-9082-f464f9d96904|[{39405, 1, 104321}]                                                                                                                                                                                                                                                                                      |Gopay         |Success       |2341.0      |WEEKENDSERU  |5000.0      |-7.85856240623962    |110.830155830973      |106980.0    |1            |\n",
      "+-----------------------+-----------+------------------------------------+------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+--------------+------------+-------------+------------+---------------------+----------------------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the transaction data\n",
    "spark.sql(\"SELECT * FROM transaction_query\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_transaction.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, TimestampType\n",
    "from pyspark.sql.functions import when, unix_timestamp\n",
    "\n",
    "# Define the actions by category\n",
    "l1_actions = ['AP', 'ATC', 'CO']  # L1 actions\n",
    "l2_actions = ['VC', 'VP', 'VI', 'SER']  # L2 actions\n",
    "l3_actions = ['SCR', 'HP', 'CL']  # L3 actions\n",
    "\n",
    "# Adding watermark to allow late data but manage memory usage\n",
    "parsed_browsing_df = parsed_browsing_df.withWatermark(\"event_ts\", \"2 minutes\")\n",
    "\n",
    "time_window = F.window(\"event_ts\", \"5 seconds\")\n",
    "\n",
    "# Perform time-based aggregation without losing original columns\n",
    "aggregated_browsing_df = parsed_browsing_df.groupBy(time_window, \"session_id\").agg(\n",
    "    F.sum(F.when(F.col(\"event_type\").isin(l1_actions), 1).otherwise(0)).alias(\"L1_count\"),\n",
    "    F.sum(F.when(F.col(\"event_type\").isin(l2_actions), 1).otherwise(0)).alias(\"L2_count\"),\n",
    "    F.sum(F.when(F.col(\"event_type\").isin(l3_actions), 1).otherwise(0)).alias(\"L3_count\"),\n",
    "    F.max(\"event_time\").alias(\"max_event_time\"),\n",
    "    F.min(\"event_time\").alias(\"min_event_time\")\n",
    ")\n",
    "\n",
    "aggregated_browsing_df = aggregated_browsing_df.join(customer_session_df.select(\"session_id\", \"customer_id\"), on=\"session_id\", how=\"left\")\n",
    "\n",
    "# Calculate the median event timestamp\n",
    "aggregated_browsing_df = aggregated_browsing_df.withColumn(\n",
    "    \"median_event_time\", ((unix_timestamp(F.col(\"max_event_time\")) + unix_timestamp(F.col(\"min_event_time\"))) / 2).cast(TimestampType())\n",
    ")\n",
    "\n",
    "# Calculate the action ratios\n",
    "aggregated_browsing_df = aggregated_browsing_df.withColumn(\n",
    "    \"total_actions\", F.col(\"L1_count\") + F.col(\"L2_count\") + F.col(\"L3_count\")\n",
    ").withColumn(\n",
    "    \"L1_ratio\", F.round(F.when(F.col(\"total_actions\") > 0, (F.col(\"L1_count\") / F.col(\"total_actions\")) * 100).otherwise(0), 2)\n",
    ").withColumn(\n",
    "    \"L2_ratio\", F.round(F.when(F.col(\"total_actions\") > 0, (F.col(\"L2_count\") / F.col(\"total_actions\")) * 100).otherwise(0), 2)\n",
    ")\n",
    "\n",
    "# To drop intermediate columns\n",
    "aggregated_browsing_df = aggregated_browsing_df.drop(\"total_actions\", \"max_event_time\", \"min_event_time\")\n",
    "\n",
    "# Extract the hour from the median event timestamp\n",
    "aggregated_browsing_df = aggregated_browsing_df.withColumn(\"extracted_hour\", F.hour(F.col(\"median_event_time\")))\n",
    "\n",
    "# Classifying the time of day based on extracted_hour\n",
    "aggregated_browsing_df = aggregated_browsing_df.withColumn(\n",
    "    \"time_of_day\", \n",
    "    F.when((F.col(\"extracted_hour\") >= 6) & (F.col(\"extracted_hour\") < 12), \"morning\")\n",
    "     .when((F.col(\"extracted_hour\") >= 12) & (F.col(\"extracted_hour\") < 18), \"afternoon\")\n",
    "     .when((F.col(\"extracted_hour\") >= 18) & (F.col(\"extracted_hour\") < 24), \"evening\")\n",
    "     .otherwise(\"night\")\n",
    ")\n",
    "\n",
    "aggregated_browsing_df = aggregated_browsing_df.drop(\"extracted_hour\", \"median_event_time\")\n",
    "\n",
    "# Calculate the age in the customer_df\n",
    "current_year = F.year(F.current_date())\n",
    "customer_df = customer_df.withColumn(\"age\", (current_year - F.year(\"birthdate\")).cast(IntegerType()))\n",
    "customer_df = customer_df.withColumn(\"first_join_year\", F.year(\"first_join_date\"))\n",
    "\n",
    "# Join customer_df with the aggregated browsing data\n",
    "aggregated_browsing_df = aggregated_browsing_df.join(\n",
    "    customer_df.select(\"customer_id\", \"gender\", \"age\", \"first_join_year\"),\n",
    "    on=\"customer_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Join transaction data with browsing data, creating the geolocation field\n",
    "aggregated_browsing_df = aggregated_browsing_df.join(\n",
    "    parsed_transaction_df.select(\"session_id\",\"Customer_id\" ,\"shipment_location_lat\", \"shipment_location_long\", \"transaction_id\", \"product_metadata\")\n",
    "    .withColumn(\"geolocation\", F.concat_ws(\", \", F.col(\"shipment_location_lat\"), F.col(\"shipment_location_long\"))),\n",
    "    on=[\"session_id\",\"customer_id\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Drop latitude and longitude after creating geolocation\n",
    "aggregated_browsing_df = aggregated_browsing_df.drop(\"shipment_location_lat\", \"shipment_location_long\")\n",
    "\n",
    "aggregated_browsing_df = aggregated_browsing_df.join(\n",
    "    fraud_transaction_df.select(\"transaction_id\")\n",
    "    .withColumn(\"fraud_status\", F.lit(\"fraud\")),\n",
    "    on=\"transaction_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Fill fraud_status for non-fraud transactions\n",
    "aggregated_browsing_df = aggregated_browsing_df.withColumn(\n",
    "    \"fraud_status\", F.when(F.col(\"fraud_status\").isNull(), \"non-fraud\").otherwise(F.col(\"fraud_status\"))\n",
    ")\n",
    "\n",
    "# Drop transaction_id if not needed\n",
    "aggregated_browsing_df = aggregated_browsing_df.drop(\"transaction_id\")\n",
    "\n",
    "# Final Selection of all the needed Columns\n",
    "final_df = parsed_browsing_df.select(\n",
    "    \"session_id\", \"event_type\", \"event_time\", \"device_type\", \"customer_id\", \"event_ts\"\n",
    ").join(\n",
    "    aggregated_browsing_df.select(\n",
    "        \"session_id\",\"customer_id\", \"L1_count\", \"L2_count\", \"L3_count\", \"L1_ratio\", \"L2_ratio\", \"time_of_day\", \n",
    "        \"gender\", \"age\", \"geolocation\", \"first_join_year\", \"fraud_status\",\"product_metadata\"\n",
    "    ),\n",
    "    on=[\"session_id\",\"customer_id\"],\n",
    "    how=\"inner\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "joined_stream = parsed_browsing_df.join(\n",
    "    parsed_transaction_df,\n",
    "    on=[\"customer_id\", \"session_id\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "num_purchase_stream = joined_stream.groupBy(\n",
    "    F.window(\"event_ts\", \"5 seconds\"),\n",
    "    \"customer_id\"\n",
    ").agg(\n",
    "    F.count(\"transaction_id\").alias(\"num_purchases\")\n",
    ")\n",
    "\n",
    "final_df_with_purchases = final_df.join(\n",
    "    num_purchase_stream.select(\"customer_id\", \"num_purchases\"),\n",
    "    on=\"customer_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "final_df_with_purchases_no_duplicates = final_df_with_purchases.dropDuplicates([\"session_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- event_time: timestamp (nullable = true)\n",
      " |-- device_type: string (nullable = true)\n",
      " |-- event_ts: timestamp (nullable = true)\n",
      " |-- L1_count: long (nullable = true)\n",
      " |-- L2_count: long (nullable = true)\n",
      " |-- L3_count: long (nullable = true)\n",
      " |-- L1_ratio: double (nullable = true)\n",
      " |-- L2_ratio: double (nullable = true)\n",
      " |-- time_of_day: string (nullable = false)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- geolocation: string (nullable = false)\n",
      " |-- first_join_year: integer (nullable = true)\n",
      " |-- fraud_status: string (nullable = true)\n",
      " |-- product_metadata: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- product_id: integer (nullable = true)\n",
      " |    |    |-- quantity: integer (nullable = true)\n",
      " |    |    |-- item_price: integer (nullable = true)\n",
      " |-- num_purchases: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df_with_purchases_no_duplicates.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "best_gbt_model = PipelineModel.load(\"best_rf_model/\")\n",
    "# Apply the loaded GBT model to predict fraud in the streaming DataFrame\n",
    "predicted_stream = best_gbt_model.transform(final_df_with_purchases_no_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- event_time: timestamp (nullable = true)\n",
      " |-- device_type: string (nullable = true)\n",
      " |-- event_ts: timestamp (nullable = true)\n",
      " |-- L1_count: long (nullable = true)\n",
      " |-- L2_count: long (nullable = true)\n",
      " |-- L3_count: long (nullable = true)\n",
      " |-- L1_ratio: double (nullable = true)\n",
      " |-- L2_ratio: double (nullable = true)\n",
      " |-- time_of_day: string (nullable = false)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- geolocation: string (nullable = false)\n",
      " |-- first_join_year: integer (nullable = true)\n",
      " |-- fraud_status: string (nullable = true)\n",
      " |-- product_metadata: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- product_id: integer (nullable = true)\n",
      " |    |    |-- quantity: integer (nullable = true)\n",
      " |    |    |-- item_price: integer (nullable = true)\n",
      " |-- num_purchases: long (nullable = false)\n",
      " |-- gender_indexed: double (nullable = false)\n",
      " |-- gender_encoded: vector (nullable = true)\n",
      " |-- fraud_status_indexed: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- scaled_features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- rf_prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_stream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_stream_save = predicted_stream.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"path\", \"Predicted_Stream\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_stream_save.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_count_data = spark.read.parquet(\"Predicted_Stream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|          session_id|count|\n",
      "+--------------------+-----+\n",
      "|a55a4726-91e8-493...|    1|\n",
      "|a48d2d01-5dc6-4b1...|    1|\n",
      "|4adf12a5-8243-448...|    1|\n",
      "|22f59ba7-bb41-446...|    1|\n",
      "|edd6bdcb-b4f0-4b0...|    1|\n",
      "|3f29b3de-cf2b-4a4...|    1|\n",
      "|a461249e-454a-443...|    1|\n",
      "+--------------------+-----+\n",
      "\n",
      "Total session_ids where rf_prediction == 1: 7\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for rows where rf_prediction == 1\n",
    "rf_prediction_1_df = fraud_count_data.filter(col(\"rf_prediction\") == 1)\n",
    "\n",
    "# Group by session_id and count the number of occurrences\n",
    "session_id_count_df = rf_prediction_1_df.groupBy(\"session_id\").count()\n",
    "\n",
    "# Show the grouped DataFrame with session_id and count\n",
    "session_id_count_df.show()\n",
    "\n",
    "# Optionally, get the total count of unique session_id where rf_prediction == 1\n",
    "unique_session_id_count = session_id_count_df.count()\n",
    "\n",
    "# Print the total number of unique session_ids\n",
    "print(f\"Total session_ids where rf_prediction == 1: {unique_session_id_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_prediction_1_df.write.mode(\"overwrite\").parquet(\"fraudCount_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------------------------------------------+--------------+\n",
      "|product_id|productDisplayName                                    |total_quantity|\n",
      "+----------+------------------------------------------------------+--------------+\n",
      "|44170     |Nike Fragrances Men Green Storm Deo                   |12            |\n",
      "|34314     |Myntra Men Orange Urban T-shirt                       |9             |\n",
      "|19837     |U.S. Polo Assn. Men Check Green Shirt                 |9             |\n",
      "|56226     |SDL by Sweet Dreams Men Green & Grey Pyjama Set       |9             |\n",
      "|58591     |ToniQ Women Coral Necklace                            |8             |\n",
      "|54619     |Fastrack Men Black Dial Watch                         |7             |\n",
      "|12463     |Basics Men Blue Checked Stoles                        |7             |\n",
      "|24583     |Lee Men Roadie Red T-shirt                            |6             |\n",
      "|13078     |Numero Uno Men White Casual Shoes                     |6             |\n",
      "|55137     |Lakme Truewear Color Crush Nail Polish 03             |6             |\n",
      "|30694     |Catwalk Women Black Heels                             |6             |\n",
      "|41742     |Catwalk Women Brown Sandals                           |5             |\n",
      "|33416     |Baggit Women Purple Wallet                            |5             |\n",
      "|13569     |Hanes Men Racer Back Navy Blue Innerwear Vests        |4             |\n",
      "|5583      |ADIDAS Men Adistreet Lux Brown Shoe                   |4             |\n",
      "|40403     |Tonga Women Beige & Brown Top                         |4             |\n",
      "|31291     |Puma Women Striped Green T-shirt                      |4             |\n",
      "|57087     |Elle Women Yellow Skirt                               |4             |\n",
      "|4188      |Disney Kids Boy's Blue Stripes Little Captain Kidswear|4             |\n",
      "|42724     |Rocia Women Brown Sandals                             |4             |\n",
      "+----------+------------------------------------------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, explode, sum\n",
    "\n",
    "# Filter for non-fraud transactions (rf_prediction == 0)\n",
    "non_fraud_transactions_df = fraud_count_data.filter(col(\"rf_prediction\") == 0)\n",
    "\n",
    "# Filter for ADD_TO_CART (ATC) events\n",
    "add_to_cart_events_df = non_fraud_transactions_df.filter(col(\"event_type\") == \"ATC\")\n",
    "\n",
    "# Explode the product_metadata column to extract individual product details\n",
    "exploded_cart_items_df = add_to_cart_events_df.withColumn(\"product\", explode(\"product_metadata\"))\n",
    "\n",
    "# Select relevant columns: session_id, product_id, product name (productDisplayName), and quantity\n",
    "product_details_df = exploded_cart_items_df.select(\n",
    "    \"session_id\", \n",
    "    col(\"product.product_id\").alias(\"product_id\"), \n",
    "    col(\"product.item_price\").alias(\"item_price\"),\n",
    "    col(\"product.quantity\").alias(\"quantity\")\n",
    ")\n",
    "\n",
    "product_details_df = product_details_df.join(\n",
    "    product_df.select(col(\"id\").alias(\"product_id\"), \"productDisplayName\"),\n",
    "    on=\"product_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Group by product_id and product_name and aggregate the total quantities for each product\n",
    "aggregated_product_quantity_df = product_details_df.groupBy(\n",
    "    \"product_id\", \n",
    "    \"productDisplayName\"\n",
    ").agg(\n",
    "    sum(\"quantity\").alias(\"total_quantity\")\n",
    ")\n",
    "\n",
    "# Order by total_quantity in descending order and limit to the top 20 products\n",
    "top_20_products_df = aggregated_product_quantity_df.orderBy(col(\"total_quantity\").desc()).limit(20)\n",
    "\n",
    "# Show the top 20 products with their product ID, name, and total quantity\n",
    "top_20_products_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the top 20 products DataFrame as a Parquet file\n",
    "top_20_products_df.write.mode(\"overwrite\").parquet(\"top_20_products_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- productDisplayName: string (nullable = true)\n",
      " |-- total_quantity: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_20_products_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7fdda58b9660>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_timestamp, col\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "fraud_count_schema = StructType([\n",
    "    StructField(\"session_id\", StringType(), True),\n",
    "    StructField(\"count\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Define schema for product stream (initially as IntegerType for product_id)\n",
    "product_schema = StructType([\n",
    "    StructField(\"product_id\", IntegerType(), True),  # Initially inferred as IntegerType\n",
    "    StructField(\"productDisplayName\", StringType(), True),\n",
    "    StructField(\"total_quantity\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Read fraudCount parquet as streaming dataframe\n",
    "fraud_count_stream = spark.readStream \\\n",
    "    .schema(fraud_count_schema) \\\n",
    "    .parquet(\"fraudCount_parquet\") \n",
    "\n",
    "# Read top_20_products parquet as streaming dataframe\n",
    "product_stream = spark.readStream \\\n",
    "    .schema(product_schema) \\\n",
    "    .parquet(\"top_20_products_parquet\") \n",
    "\n",
    "# Cast product_id to StringType\n",
    "product_stream = product_stream.withColumn(\"product_id\", col(\"product_id\").cast(StringType()))\n",
    "product_stream = product_stream.withColumn(\"total_quantity\", col(\"total_quantity\").cast(StringType()))\n",
    "\n",
    "fraud_count_stream.selectExpr(\n",
    "    \"CAST(session_id AS STRING) AS key\",\n",
    "    \"to_json(struct(*)) AS value\"\n",
    ").writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"topic\", \"fraud_count_topic\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7fdd37eb37f0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send product stream to Kafka with timestamp\n",
    "product_stream.selectExpr(\n",
    "    \"CAST(product_id AS STRING) AS key\",\n",
    "    \"to_json(struct(*)) AS value\"\n",
    ").writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"topic\", \"top_products_topic\") \\\n",
    "    .start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
